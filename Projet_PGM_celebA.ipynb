{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cA3ReeibNeON"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "from torchvision import utils\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "import argparse\n",
        "from torchvision import datasets, transforms\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels, int_channels=128):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # Convolutions with dilations\n",
        "        self.conv11 = nn.Conv2d(input_channels, int_channels, kernel_size=3, stride=1, padding=1, dilation=1)\n",
        "        self.conv12 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=1, dilation=1)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=2, dilation=2)\n",
        "        self.conv22 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=2, dilation=2)\n",
        "\n",
        "        self.conv31 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=4, dilation=4)\n",
        "        self.conv32 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=4, dilation=4)\n",
        "        self.conv33 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=4, dilation=4)\n",
        "\n",
        "        # Pooling for downsampling\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Upsampling convolutions\n",
        "        self.convu21 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.convu22 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.convu11 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.convu12 = nn.Conv2d(int_channels, int_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Output layer\n",
        "        self.convout = nn.Conv2d(int_channels, output_channels, kernel_size=1, stride=1)\n",
        "        torch.nn.init.kaiming_normal_(self.convout.weight, nonlinearity='linear')\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First block\n",
        "        x11 = F.elu(self.conv11(x))\n",
        "        x12 = self.conv12(x11)\n",
        "        x12_pooled = self.pool(x12)  # Downsample\n",
        "\n",
        "        # Second block\n",
        "        x21 = F.elu(self.conv21(x12_pooled))\n",
        "        x22 = self.conv22(x21)\n",
        "        x22_pooled = self.pool(x22)  # Downsample\n",
        "\n",
        "        # Third block\n",
        "        x31 = F.elu(self.conv31(x22_pooled))\n",
        "        x32 = F.elu(self.conv32(x31))\n",
        "        x33 = self.conv33(x32)\n",
        "\n",
        "        # Upsampling with bilinear interpolation\n",
        "        xu20 = F.interpolate(x33, size=x22.shape[2:], mode='bilinear', align_corners=False)\n",
        "        xu21 = F.elu((xu20 + x22) / math.sqrt(2))\n",
        "        xu22 = F.elu(self.convu21(xu21))\n",
        "        xu23 = self.convu22(xu22)\n",
        "\n",
        "        xu10 = F.interpolate(xu23, size=x12.shape[2:], mode='bilinear', align_corners=False)\n",
        "        xu11 = F.elu((xu10 + x12) / math.sqrt(2))\n",
        "        xu12 = F.elu(self.convu11(xu11))\n",
        "        xu13 = F.elu(self.convu12(xu12))\n",
        "\n",
        "        # Final output\n",
        "        out = self.convout(xu13)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UNet_Res(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels, depth=3, int_channels=128):\n",
        "        super(UNet_Res, self).__init__()\n",
        "\n",
        "        # Initial UNet with 128 filters\n",
        "        self.unetin = UNet(input_channels, int_channels)\n",
        "\n",
        "        # Output UNet with 128 filters\n",
        "        self.unetout = UNet(int_channels, output_channels)\n",
        "\n",
        "        # Intermediate cascades with doubled filters\n",
        "        self.unets = nn.ModuleList(\n",
        "            [UNet(int_channels * (2**i), int_channels * (2**(i + 1))) for i in range(depth)]\n",
        "        )\n",
        "\n",
        "        # Instance normalization\n",
        "        self.norm = nn.InstanceNorm2d(int_channels, affine=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.unetin(x)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        for unet in self.unets:\n",
        "            res_input = self.norm(x)\n",
        "            res_output = unet(res_input)\n",
        "            res_output = self.norm(res_output)\n",
        "            x = x + res_output\n",
        "\n",
        "        x = self.unetout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Denoiser(nn.Module):\n",
        "    def __init__(self, noisy_input_channels, output_channels, depth=3):\n",
        "        super(Denoiser, self).__init__()\n",
        "        # For CelebA, the first cascade has 128 filters, subsequent cascades double the filters\n",
        "        self.unet_res = UNet_Res(noisy_input_channels, output_channels, depth=depth)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.unet_res(x)\n"
      ],
      "metadata": {
        "id": "zqFr8KMmBObM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image(im,name):\n",
        "    normalized = im-torch.min(im)\n",
        "    normalized = normalized/torch.max(normalized)\n",
        "    utils.save_image(normalized,name)\n",
        "\n",
        "\n",
        "class dotdict(dict):\n",
        "        \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "        __getattr__ = dict.get\n",
        "        __setattr__ = dict.__setitem__\n",
        "        __delattr__ = dict.__delitem__\n"
      ],
      "metadata": {
        "id": "aki_q-tnOWKT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigmas = 5*torch.pow(torch.ones(10)*0.6,torch.arange(10))\n",
        "\n",
        "\n",
        "def forward(data, model):\n",
        "    im = data\n",
        "\n",
        "    # parameters of the langevin dynamics steps\n",
        "    ind_randoms= torch.randint(0, sigmas.shape[0], (data.shape[0],), device = data.device)\n",
        "    sigmas_batch = sigmas[ind_randoms]\n",
        "\n",
        "    noise_in = torch.randn_like(im)\n",
        "    im_input = (sigmas_batch[:,None,None,None]*noise_in+im)\n",
        "    #im_input_norm = torch.sqrt(torch.sum(im_input**2,dim=(1,2,3)))\n",
        "    #im_input_renormalized = (im_input-torch.mean(im_input,dim=(1,2,3))[:,None,None,None])/im_input_norm[:,None,None,None]\n",
        "    # we append the sigmas to the model input as a new dimension of the image\n",
        "\n",
        "    #mod_input = torch.cat((im_input, sigmas_batch[:,None,None,None].expand(im.shape)), dim=1)\n",
        "    mod_input = torch.cat((im_input[:, :1], sigmas_batch[:, None, None, None].expand(-1, 1, im_input.shape[2], im_input.shape[3])), dim=1)\n",
        "\n",
        "    pred_score = model(mod_input)/sigmas_batch[:,None,None,None] # we divide by sigma such that the variance\n",
        "    # of the last layer is constant and equal to 1\n",
        "    # corrected image using the score expression\n",
        "    im_corrected = im_input+sigmas_batch[:,None,None,None]**2*pred_score\n",
        "\n",
        "    score = -noise_in/sigmas_batch[:,None,None,None]\n",
        "    square_norm = torch.sum((pred_score -score)**2,(1,2,3)) # square norm of loss per image\n",
        "    loss = torch.sum(sigmas_batch**2*square_norm)\n",
        "    return loss, im_input, im_corrected\n",
        "\n",
        "\n",
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss, im_input, im_corrected= forward(data, model)\n",
        "\n",
        "        loss.backward()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if (batch_idx+1) % args.log_interval  == 0:\n",
        "            running_loss = running_loss/(args.log_interval*args.batch_size)\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), running_loss))\n",
        "            running_loss = 0\n",
        "            if args.dry_run:\n",
        "                break\n",
        "\n",
        "nid= \"vnoise\"\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    ctime = time.time()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            im = data\n",
        "            loss, im_input, corr= forward(data, model)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set {:.4f} Average loss: {:.4f} \\n'.format(time.time()-ctime,test_loss))\n",
        "    orig = im\n",
        "    noisy = im_input\n",
        "    save_image(noisy[:10],\"/content/drive/My Drive/Télécom/3A/MVA/PGM/im/noisy_celeb.jpg\")\n",
        "    save_image(corr[:10],\"/content/drive/My Drive/Télécom/3A/MVA/PGM/im/corrected_celeb.jpg\")\n",
        "    save_image(orig[:10],\"/content/drive/My Drive/Télécom/3A/MVA/PGM/im/originals_celeb.jpg\")\n",
        "    gen_shape = list(im.shape)\n",
        "    gen_shape[0] = 10\n",
        "    gen_im = sampleLangevin(model, device, gen_shape)\n",
        "    save_image(gen_im, \"/content/drive/My Drive/Télécom/3A/MVA/PGM/im/generated_celeb.jpg\")\n",
        "\n",
        "\n",
        "def sampleLangevin(model,device, im_shape, epsilon = 25e-5, T=100):\n",
        "    print(\"generating images...\")\n",
        "    with torch.no_grad():\n",
        "        xt = torch.randn(im_shape, device = device)*(1+sigmas[0])\n",
        "        for i in range(sigmas.shape[0]):\n",
        "            sigmai = sigmas[i]\n",
        "            alphai = epsilon*sigmai**2/sigmas[-1]**2\n",
        "            for t in range(T):\n",
        "                zt = torch.randn_like(xt)\n",
        "                xt_norm = torch.sqrt(torch.sum(xt**2,dim=(1,2,3)))\n",
        "                xt_renormalized= (xt-torch.mean(xt, dim=(1,2,3))[:,None,None,None])/xt_norm[:,None,None,None]\n",
        "                mod_input = torch.cat((xt,sigmai[None,None,None,None].expand(xt.shape)), dim=1)\n",
        "                score = model(mod_input)/sigmai\n",
        "                xt = xt + alphai/2*score+torch.sqrt(alphai)*zt\n",
        "    print(\"images generated ! \")\n",
        "    return xt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    global sigmas\n",
        "    # Training settings\n",
        "    args_dict = {'batch_size' : 64, 'test_batch_size' : 128, 'epochs' :40, 'lr' : 0.001, 'gamma' : 0.9, 'no_cuda' :False, 'dry_run':False, 'seed': 1, 'log_interval' : 200, 'save_model' :True, 'only_test':False, 'model_path':\"denoiser.pt\", 'load_model_from_disk':False}\n",
        "    args = dotdict(args_dict)\n",
        "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "    if use_cuda:\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    train_kwargs = {'batch_size': args.batch_size}\n",
        "    test_kwargs = {'batch_size': args.test_batch_size}\n",
        "    if use_cuda:\n",
        "        cuda_kwargs = {'num_workers': 1,\n",
        "                       'pin_memory': True,\n",
        "                       'shuffle': True}\n",
        "        train_kwargs.update(cuda_kwargs)\n",
        "        test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "    # loading dataset\n",
        "    transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    dataset1 = datasets.CelebA(root='data/celeba', split='train', download=True, transform=transform)\n",
        "    dataset2 = datasets.CelebA(root='data/celeba', split='test', download=True, transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "    model = Denoiser(2,1,depth = 3).to(device)\n",
        "    if args.load_model_from_disk:\n",
        "        model.load_state_dict(torch.load(args.model_path, weights_only= True))\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "\n",
        "    sigmas = sigmas.to(device)\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        if not args.only_test:\n",
        "            train(args, model , device, train_loader, optimizer, epoch)\n",
        "            scheduler.step()\n",
        "        test(model,  device, test_loader)\n",
        "\n",
        "    if args.save_model:\n",
        "        torch.save(model.state_dict(), args.model_path)\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "7fyhlbQAOfvQ",
        "outputId": "3d7cb525-742b-4fbc-b753-7202de51fdf3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a620aca17ad7>\u001b[0m in \u001b[0;36m<cell line: 154>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-a620aca17ad7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m     ])\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdataset1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCelebA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/celeba'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mdataset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCelebA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/celeba'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/celeba.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, target_type, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/celeba.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mdownload_file_from_google_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"img_align_celeba.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_file_from_google_drive\u001b[0;34m(file_id, root, filename, md5)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imread\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im = imread(\"/content/drive/My Drive/Télécom/3A/MVA/PGM/im/generated.jpg\")\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1pQpkSx8RSIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WzNEvuXtTGhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}