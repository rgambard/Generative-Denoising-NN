{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63ec39f",
   "metadata": {},
   "source": [
    "## Implement annealed HMC sampling for MNIST generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZIYIQ4aZroBR",
   "metadata": {
    "id": "ZIYIQ4aZroBR"
   },
   "source": [
    "## Model Definition\n",
    "First, we defined the sigmas of perturbation distibutsions.\n",
    "$$ q_{\\sigma}(x)=\\int p_{data}(t)\\mathcal(x \\vert t, \\sigma^2\\mathbf{I}) $$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "However, $s_{\\theta}(x)=\\nabla_{x}{\\log}q_{\\sigma}(x)\\approx\\nabla_{x}{\\log}p_{data}(x)$ is true only when the noise is small enough s.t. $q_{\\sigma}(x) \\approx p_{data}(x)$.\n",
    "Therefore, by using multiple noise levels, we can obtain a sequence of noise-perturbed distributions that converge to the true data distribution.\n",
    "\n",
    "<br>\n",
    "\n",
    "Conditional perturbation distribution according to the step ($i$) is:\n",
    "$$ q_{\\sigma_{i}}(\\tilde{x} \\vert x)=\\mathcal{N}(\\tilde{x} \\vert x, \\sigma_{i}^2\\mathbf{I}). \\ \\ \\text{In other word},\\ \\ \\ \\tilde{x}=x+\\sigma_{i}*z,\\ \\ where\\ \\ z\\sim\\mathcal{N}(0, \\mathbf{I})\\ \\ \\text{and}\\ \\ \\frac{\\sigma_{1}}{\\sigma_{2}}=\\frac{\\sigma_{2}}{\\sigma_{3}}=\\cdots=\\frac{\\sigma_{L-1}}{\\sigma_{L}} > 1$$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "And, we defined a score model depend on sigmas.\n",
    "$$ \\mathbf{s}_{\\theta}(\\tilde{x}, \\sigma_i) \\approx \\nabla_{\\tilde{x}} \\log{q_{\\sigma_i} }(\\tilde{x}\\vert{x})$$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "If perturbation distributsions were defined by sigmas, then the score of perturbation distribution is:\n",
    "$$ \\nabla_{\\tilde{x}}\\log q_{\\sigma_i}(\\tilde{x}\\vert{x})=-\\frac{(\\tilde{x}-x)}{\\sigma_i^2}=-\\frac{z}{\\sigma_i} $$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Then, we can use the objective function for noise conditional score network via score matching.\n",
    "\n",
    "$$ \\mathcal{L}(\\theta, \\{ \\sigma_{i}\\}_{i=1}^L)=\\frac{1}{L}\\sum_{i=1}^L\\lambda({\\sigma_i})\\mathcal{l}(\\theta;\\sigma_i),\\ \\ \\ \n",
    "where\\ \\ \\ \\mathcal{l}(\\theta;\\sigma_i)=\\frac{1}{2}\\mathbb{E}_{p_{data}(x)}\\mathbb{E}_{\\tilde{x}\\sim\\mathcal{N}(x,\\sigma_i^2\\mathbf{I})}[\\Vert \\mathbf{s}_{\\theta}(\\tilde{x}, \\sigma_i)+\\frac{\\tilde{x}-x}{\\sigma_i^2}\\Vert^2_2]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-digit",
   "metadata": {
    "id": "printable-digit"
   },
   "source": [
    "# Define Model From \n",
    "\n",
    "$\\href{https://github.com/ermongroup/ncsn/}{NCSN\\ GitHub}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HPInI4n2IHYG",
   "metadata": {
    "id": "HPInI4n2IHYG"
   },
   "source": [
    "## Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "IXNcjGtS5Xvg",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:24:25.480309Z",
     "iopub.status.busy": "2024-12-17T10:24:25.480015Z",
     "iopub.status.idle": "2024-12-17T10:24:29.245080Z",
     "shell.execute_reply": "2024-12-17T10:24:29.243201Z",
     "shell.execute_reply.started": "2024-12-17T10:24:25.480280Z"
    },
    "id": "IXNcjGtS5Xvg",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3718594867.py:8: DeprecationWarning: Please import `rotate` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.interpolation import rotate\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amateur-wilson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:24:29.246960Z",
     "iopub.status.busy": "2024-12-17T10:24:29.246543Z",
     "iopub.status.idle": "2024-12-17T10:24:29.420559Z",
     "shell.execute_reply": "2024-12-17T10:24:29.419701Z",
     "shell.execute_reply.started": "2024-12-17T10:24:29.246924Z"
    },
    "id": "amateur-wilson",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, bias=False):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=bias)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1, bias=False):\n",
    "    \"1x1 convolution\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                     padding=0, bias=bias)\n",
    "\n",
    "\n",
    "def dilated_conv3x3(in_planes, out_planes, dilation, bias=True):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, padding=dilation, dilation=dilation, bias=bias)\n",
    "\n",
    "\n",
    "class ConditionalBatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, bias=True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bias = bias\n",
    "        self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
    "        if self.bias:\n",
    "            self.embed = nn.Embedding(num_classes, num_features * 2)\n",
    "            self.embed.weight.data[:, :num_features].uniform_()  # Initialise scale at N(1, 0.02)\n",
    "            self.embed.weight.data[:, num_features:].zero_()  # Initialise bias at 0\n",
    "        else:\n",
    "            self.embed = nn.Embedding(num_classes, num_features)\n",
    "            self.embed.weight.data.uniform_()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.bn(x)\n",
    "        if self.bias:\n",
    "            gamma, beta = self.embed(y).chunk(2, dim=1)\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)\n",
    "        else:\n",
    "            gamma = self.embed(y)\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * out\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConditionalInstanceNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, bias=True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bias = bias\n",
    "        self.instance_norm = nn.InstanceNorm2d(num_features, affine=False, track_running_stats=False)\n",
    "        if bias:\n",
    "            self.embed = nn.Embedding(num_classes, num_features * 2)\n",
    "            self.embed.weight.data[:, :num_features].uniform_()  # Initialise scale at N(1, 0.02)\n",
    "            self.embed.weight.data[:, num_features:].zero_()  # Initialise bias at 0\n",
    "        else:\n",
    "            self.embed = nn.Embedding(num_classes, num_features)\n",
    "            self.embed.weight.data.uniform_()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h = self.instance_norm(x)\n",
    "        if self.bias:\n",
    "            gamma, beta = self.embed(y).chunk(2, dim=-1)\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * h + beta.view(-1, self.num_features, 1, 1)\n",
    "        else:\n",
    "            gamma = self.embed(y)\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * h\n",
    "        return out\n",
    "\n",
    "\n",
    "class CRPBlock(nn.Module):\n",
    "    def __init__(self, features, n_stages, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(n_stages):\n",
    "            self.convs.append(conv3x3(features, features, stride=1, bias=False))\n",
    "        self.n_stages = n_stages\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(x)\n",
    "        path = x\n",
    "        for i in range(self.n_stages):\n",
    "            path = self.maxpool(path)\n",
    "            path = self.convs[i](path)\n",
    "            x = path + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class CondCRPBlock(nn.Module):\n",
    "    def __init__(self, features, n_stages, num_classes, normalizer, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        for i in range(n_stages):\n",
    "            self.norms.append(normalizer(features, num_classes, bias=True))\n",
    "            self.convs.append(conv3x3(features, features, stride=1, bias=False))\n",
    "        self.n_stages = n_stages\n",
    "        self.maxpool = nn.AvgPool2d(kernel_size=5, stride=1, padding=2)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.act(x)\n",
    "        path = x\n",
    "        for i in range(self.n_stages):\n",
    "            path = self.norms[i](path, y)\n",
    "            path = self.maxpool(path)\n",
    "            path = self.convs[i](path)\n",
    "            x = path + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class CondRCUBlock(nn.Module):\n",
    "    def __init__(self, features, n_blocks, n_stages, num_classes, normalizer, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "\n",
    "        for i in range(n_blocks):\n",
    "            for j in range(n_stages):\n",
    "                setattr(self, '{}_{}_norm'.format(i + 1, j + 1), normalizer(features, num_classes, bias=True))\n",
    "                setattr(self, '{}_{}_conv'.format(i + 1, j + 1),\n",
    "                        conv3x3(features, features, stride=1, bias=False))\n",
    "\n",
    "        self.stride = 1\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_stages = n_stages\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        for i in range(self.n_blocks):\n",
    "            residual = x\n",
    "            for j in range(self.n_stages):\n",
    "                x = getattr(self, '{}_{}_norm'.format(i + 1, j + 1))(x, y)\n",
    "                x = self.act(x)\n",
    "                x = getattr(self, '{}_{}_conv'.format(i + 1, j + 1))(x)\n",
    "            x += residual\n",
    "        return x\n",
    "\n",
    "\n",
    "class CondMSFBlock(nn.Module):\n",
    "    def __init__(self, in_planes, features, num_classes, normalizer):\n",
    "        \"\"\"\n",
    "        :param in_planes: tuples of input planes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert isinstance(in_planes, list) or isinstance(in_planes, tuple)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.features = features\n",
    "\n",
    "        for i in range(len(in_planes)):\n",
    "            self.convs.append(conv3x3(in_planes[i], features, stride=1, bias=True))\n",
    "            self.norms.append(normalizer(in_planes[i], num_classes, bias=True))\n",
    "\n",
    "    def forward(self, xs, y, shape):\n",
    "        sums = torch.zeros(xs[0].shape[0], self.features, *shape, device=xs[0].device)\n",
    "        for i in range(len(self.convs)):\n",
    "            h = self.norms[i](xs[i], y)\n",
    "            h = self.convs[i](h)\n",
    "            h = F.interpolate(h, size=shape, mode='bilinear', align_corners=True)\n",
    "            sums += h\n",
    "        return sums\n",
    "\n",
    "\n",
    "class CondRefineBlock(nn.Module):\n",
    "    def __init__(self, in_planes, features, num_classes, normalizer, act=nn.ReLU(), start=False, end=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert isinstance(in_planes, tuple) or isinstance(in_planes, list)\n",
    "        self.n_blocks = n_blocks = len(in_planes)\n",
    "\n",
    "        self.adapt_convs = nn.ModuleList()\n",
    "        for i in range(n_blocks):\n",
    "            self.adapt_convs.append(\n",
    "                CondRCUBlock(in_planes[i], 2, 2, num_classes, normalizer, act)\n",
    "            )\n",
    "\n",
    "        self.output_convs = CondRCUBlock(features, 3 if end else 1, 2, num_classes, normalizer, act)\n",
    "\n",
    "        if not start:\n",
    "            self.msf = CondMSFBlock(in_planes, features, num_classes, normalizer)\n",
    "\n",
    "        self.crp = CondCRPBlock(features, 2, num_classes, normalizer, act)\n",
    "\n",
    "    def forward(self, xs, y, output_shape):\n",
    "        assert isinstance(xs, tuple) or isinstance(xs, list)\n",
    "        hs = []\n",
    "        for i in range(len(xs)):\n",
    "            h = self.adapt_convs[i](xs[i], y)\n",
    "            hs.append(h)\n",
    "\n",
    "        if self.n_blocks > 1:\n",
    "            h = self.msf(hs, y, output_shape)\n",
    "        else:\n",
    "            h = hs[0]\n",
    "\n",
    "        h = self.crp(h, y)\n",
    "        h = self.output_convs(h, y)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class ConvMeanPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size=3, biases=True, adjust_padding=False):\n",
    "        super().__init__()\n",
    "        if not adjust_padding:\n",
    "            self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=kernel_size // 2, bias=biases)\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "                nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=kernel_size // 2, bias=biases)\n",
    "            )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.conv(inputs)\n",
    "        output = sum(\n",
    "            [output[:, :, ::2, ::2], output[:, :, 1::2, ::2], output[:, :, ::2, 1::2], output[:, :, 1::2, 1::2]]) / 4.\n",
    "        return output\n",
    "\n",
    "\n",
    "class MeanPoolConv(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size=3, biases=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=kernel_size // 2, bias=biases)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = inputs\n",
    "        output = sum(\n",
    "            [output[:, :, ::2, ::2], output[:, :, 1::2, ::2], output[:, :, ::2, 1::2], output[:, :, 1::2, 1::2]]) / 4.\n",
    "        return self.conv(output)\n",
    "\n",
    "\n",
    "class UpsampleConv(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size=3, biases=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=kernel_size // 2, bias=biases)\n",
    "        self.pixelshuffle = nn.PixelShuffle(upscale_factor=2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = inputs\n",
    "        output = torch.cat([output, output, output, output], dim=1)\n",
    "        output = self.pixelshuffle(output)\n",
    "        return self.conv(output)\n",
    "\n",
    "\n",
    "class ConditionalResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_classes, resample=None, act=nn.ELU(),\n",
    "                 normalization=ConditionalBatchNorm2d, adjust_padding=False, dilation=None):\n",
    "        super().__init__()\n",
    "        self.non_linearity = act\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.resample = resample\n",
    "        if resample == 'down':\n",
    "            if dilation is not None:\n",
    "                self.conv1 = dilated_conv3x3(input_dim, input_dim, dilation=dilation)\n",
    "                self.normalize2 = normalization(input_dim, num_classes)\n",
    "                self.conv2 = dilated_conv3x3(input_dim, output_dim, dilation=dilation)\n",
    "                conv_shortcut = partial(dilated_conv3x3, dilation=dilation)\n",
    "            else:\n",
    "                self.conv1 = nn.Conv2d(input_dim, input_dim, 3, stride=1, padding=1)\n",
    "                self.normalize2 = normalization(input_dim, num_classes)\n",
    "                self.conv2 = ConvMeanPool(input_dim, output_dim, 3, adjust_padding=adjust_padding)\n",
    "                conv_shortcut = partial(ConvMeanPool, kernel_size=1, adjust_padding=adjust_padding)\n",
    "\n",
    "        elif resample is None:\n",
    "            if dilation is not None:\n",
    "                conv_shortcut = partial(dilated_conv3x3, dilation=dilation)\n",
    "                self.conv1 = dilated_conv3x3(input_dim, output_dim, dilation=dilation)\n",
    "                self.normalize2 = normalization(output_dim, num_classes)\n",
    "                self.conv2 = dilated_conv3x3(output_dim, output_dim, dilation=dilation)\n",
    "            else:\n",
    "                conv_shortcut = nn.Conv2d\n",
    "                self.conv1 = nn.Conv2d(input_dim, output_dim, kernel_size=3, stride=1, padding=1)\n",
    "                self.normalize2 = normalization(output_dim, num_classes)\n",
    "                self.conv2 = nn.Conv2d(output_dim, output_dim, kernel_size=3, stride=1, padding=1)\n",
    "        else:\n",
    "            raise Exception('invalid resample value')\n",
    "\n",
    "        if output_dim != input_dim or resample is not None:\n",
    "            self.shortcut = conv_shortcut(input_dim, output_dim)\n",
    "\n",
    "        self.normalize1 = normalization(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        output = self.normalize1(x, y)\n",
    "        output = self.non_linearity(output)\n",
    "        output = self.conv1(output)\n",
    "        output = self.normalize2(output, y)\n",
    "        output = self.non_linearity(output)\n",
    "        output = self.conv2(output)\n",
    "\n",
    "        if self.output_dim == self.input_dim and self.resample is None:\n",
    "            shortcut = x\n",
    "        else:\n",
    "            shortcut = self.shortcut(x)\n",
    "\n",
    "        return shortcut + output\n",
    "\n",
    "\n",
    "class ConditionalInstanceNorm2dPlus(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, bias=True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bias = bias\n",
    "        self.instance_norm = nn.InstanceNorm2d(num_features, affine=False, track_running_stats=False)\n",
    "        if bias:\n",
    "            self.embed = nn.Embedding(num_classes, num_features * 3)\n",
    "            self.embed.weight.data[:, :2 * num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n",
    "            self.embed.weight.data[:, 2 * num_features:].zero_()  # Initialise bias at 0\n",
    "        else:\n",
    "            self.embed = nn.Embedding(num_classes, 2 * num_features)\n",
    "            self.embed.weight.data.normal_(1, 0.02)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        means = torch.mean(x, dim=(2, 3))\n",
    "        m = torch.mean(means, dim=-1, keepdim=True)\n",
    "        v = torch.var(means, dim=-1, keepdim=True)\n",
    "        means = (means - m) / (torch.sqrt(v + 1e-5))\n",
    "        h = self.instance_norm(x)\n",
    "\n",
    "        if self.bias:\n",
    "            gamma, alpha, beta = self.embed(y).chunk(3, dim=-1)\n",
    "            h = h + means[..., None, None] * alpha[..., None, None]\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * h + beta.view(-1, self.num_features, 1, 1)\n",
    "        else:\n",
    "            gamma, alpha = self.embed(y).chunk(2, dim=-1)\n",
    "            h = h + means[..., None, None] * alpha[..., None, None]\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * h\n",
    "        return out\n",
    "\n",
    "\n",
    "class CondRefineNetDilated(nn.Module):\n",
    "    def __init__(self,  device, L):\n",
    "        super().__init__()\n",
    "        # self.norm = ConditionalInstanceNorm2d\n",
    "        self.norm = ConditionalInstanceNorm2dPlus\n",
    "        self.ngf = 64\n",
    "        self.num_classes = L\n",
    "        self.act = act = nn.ELU()\n",
    "        self.device = device\n",
    "        # self.act = act = nn.ReLU(True)\n",
    "\n",
    "        self.begin_conv = nn.Conv2d(1, self.ngf, 3, stride=1, padding=1)\n",
    "        self.normalizer = self.norm(self.ngf, self.num_classes)\n",
    "\n",
    "        self.end_conv = nn.Conv2d(self.ngf, 1, 3, stride=1, padding=1)\n",
    "\n",
    "        self.res1 = nn.ModuleList([\n",
    "            ConditionalResidualBlock(self.ngf, self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                     normalization=self.norm),\n",
    "            ConditionalResidualBlock(self.ngf, self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                     normalization=self.norm)]\n",
    "        )\n",
    "\n",
    "        self.res2 = nn.ModuleList([\n",
    "            ConditionalResidualBlock(self.ngf, 2 * self.ngf, self.num_classes, resample='down', act=act,\n",
    "                                     normalization=self.norm),\n",
    "            ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                     normalization=self.norm)]\n",
    "        )\n",
    "\n",
    "        self.res3 = nn.ModuleList([\n",
    "            ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample='down', act=act,\n",
    "                                     normalization=self.norm, dilation=2),\n",
    "            ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                     normalization=self.norm, dilation=2)]\n",
    "        )\n",
    "\n",
    "        self.res4 = nn.ModuleList([\n",
    "            ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample='down', act=act,\n",
    "                                     normalization=self.norm, adjust_padding=True, dilation=4),\n",
    "            ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                     normalization=self.norm, dilation=4)]\n",
    "        )\n",
    "\n",
    "\n",
    "        self.refine1 = CondRefineBlock([2 * self.ngf], 2 * self.ngf, self.num_classes, self.norm, act=act, start=True)\n",
    "        self.refine2 = CondRefineBlock([2 * self.ngf, 2 * self.ngf], 2 * self.ngf, self.num_classes, self.norm, act=act)\n",
    "        self.refine3 = CondRefineBlock([2 * self.ngf, 2 * self.ngf], self.ngf, self.num_classes, self.norm, act=act)\n",
    "        self.refine4 = CondRefineBlock([self.ngf, self.ngf], self.ngf, self.num_classes, self.norm, act=act, end=True)\n",
    "        \n",
    "        self.to(device = device)\n",
    "\n",
    "    def _compute_cond_module(self, module, x, y):\n",
    "        for m in module:\n",
    "            x = m(x, y)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        output = self.begin_conv(x)\n",
    "\n",
    "        layer1 = self._compute_cond_module(self.res1, output, y)\n",
    "        layer2 = self._compute_cond_module(self.res2, layer1, y)\n",
    "        layer3 = self._compute_cond_module(self.res3, layer2, y)\n",
    "        layer4 = self._compute_cond_module(self.res4, layer3, y)\n",
    "\n",
    "        ref1 = self.refine1([layer4], y, layer4.shape[2:])\n",
    "        ref2 = self.refine2([layer3, ref1], y, layer3.shape[2:])\n",
    "        ref3 = self.refine3([layer2, ref2], y, layer2.shape[2:])\n",
    "        output = self.refine4([layer1, ref3], y, layer1.shape[2:])\n",
    "\n",
    "        output = self.normalizer(output, y)\n",
    "        output = self.act(output)\n",
    "        output = self.end_conv(output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m8nq3PssILnq",
   "metadata": {
    "id": "m8nq3PssILnq"
   },
   "source": [
    "## Score Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "owned-quality",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:24:30.872017Z",
     "iopub.status.busy": "2024-12-17T10:24:30.871693Z",
     "iopub.status.idle": "2024-12-17T10:24:30.881257Z",
     "shell.execute_reply": "2024-12-17T10:24:30.880314Z",
     "shell.execute_reply.started": "2024-12-17T10:24:30.871989Z"
    },
    "id": "owned-quality",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, device, n_steps, sigma_min, sigma_max):\n",
    "        '''\n",
    "        Score Network.\n",
    "\n",
    "        n_steps   : perturbation schedule steps (Langevin Dynamic step)\n",
    "        sigma_min : sigma min of perturbation schedule\n",
    "        sigma_min : sigma max of perturbation schedule\n",
    "\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.sigmas = torch.exp(torch.linspace(start=math.log(sigma_max), end=math.log(sigma_min), steps = n_steps)).to(device = device)\n",
    "        self.conv_layer = CondRefineNetDilated(device, n_steps)\n",
    "        self.to(device = device)\n",
    "\n",
    "    # Loss Function\n",
    "    def loss_fn(self, x, idx=None):\n",
    "        '''\n",
    "        This function performed when only training phase.\n",
    "\n",
    "        x          : real data if idx==None else perturbation data\n",
    "        idx        : if None (training phase), we perturbed random index. Else (inference phase), it is recommended that you specify.\n",
    "\n",
    "        '''\n",
    "        scores, target, sigma = self.forward(x, idx=idx, get_target=True)\n",
    "        target = target.view(target.shape[0], -1)\n",
    "        scores = scores.view(scores.shape[0], -1)        \n",
    "        losses = torch.square(scores - target).mean(dim=-1) * sigma.squeeze() ** 2\n",
    "        return losses.mean(dim=0)\n",
    "\n",
    "    # S(theta, sigma)\n",
    "    def forward(self, x, idx=None, get_target=False):\n",
    "        '''\n",
    "        x          : real data if idx==None else perturbation data\n",
    "        idx        : if None (training phase), we perturbed random index. Else (inference phase), it is recommended that you specify.\n",
    "        get_target : if True (training phase), target and sigma is returned with output (score prediction)\n",
    "\n",
    "        '''\n",
    "\n",
    "        if idx == None:\n",
    "            idx = torch.randint(0, len(self.sigmas), (x.size(0), 1)).to(device = self.device)\n",
    "            used_sigmas = self.sigmas[idx][:, :, None, None]\n",
    "            noise = torch.randn_like(x)\n",
    "            x_tilde = x + noise * used_sigmas\n",
    "            idx = idx.squeeze()\n",
    "        else:\n",
    "            idx = torch.Tensor([idx for _ in range(x.size(0))]).to(device = self.device).long()\n",
    "            x_tilde = x\n",
    "            \n",
    "        if get_target:\n",
    "            target = - 1 / (used_sigmas ) * noise \n",
    "\n",
    "            \n",
    "        output = self.conv_layer(x_tilde, idx)\n",
    "\n",
    "        return (output, target, used_sigmas) if get_target else output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-addiction",
   "metadata": {
    "id": "junior-addiction"
   },
   "source": [
    "## Sampling, with annealed Langevin dynamic and annealed HMC\n",
    "\n",
    "* Annealed Langevin dynamic $$\\tilde{x}_{t} = \\tilde{x}_{t-1}+\\frac{\\alpha_{i}}{2}\\nabla_{\\tilde{x}_{t-1}}{\\log}p_{\\sigma_{i}}(\\tilde{x}_{t-1})+\\sqrt{\\alpha_{i}}z_{t}\\ \\ \\text{where, } i\\in [1, L]\\ \\  \\text{and}\\ \\  t\\in[1,T]$$\n",
    "\n",
    "* In HMC we update auxiliary momentum variable and our samples with by leapfrog integration to approximate solution of Hamiltonian equations. Then apply HM acceptance criterion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pretty-willow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:24:38.551951Z",
     "iopub.status.busy": "2024-12-17T10:24:38.551031Z",
     "iopub.status.idle": "2024-12-17T10:24:38.560365Z",
     "shell.execute_reply": "2024-12-17T10:24:38.559463Z",
     "shell.execute_reply.started": "2024-12-17T10:24:38.551914Z"
    },
    "id": "pretty-willow",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AnnealedLangevinDynamic():\n",
    "    def __init__(self, sigma_min, sigma_max, n_steps, annealed_step, score_fn, device, eps = 1e-1):\n",
    "        '''\n",
    "        sigma_min : minimum sigmas of perturbation schedule \n",
    "        sigma_max : maximum sigmas of perturbation schedule \n",
    "        L         : iteration step of Langevin dynamic\n",
    "        T         : annelaed step of annealed Langevin dynamic\n",
    "        score_fn  : trained score network\n",
    "        eps       : coefficient of step size\n",
    "        '''\n",
    "        self.process = torch.exp(torch.linspace(start=math.log(sigma_max), end=math.log(sigma_min), steps = n_steps))\n",
    "        self.step_size = eps * (self.process / self.process[-1] ) ** 2\n",
    "        self.score_fn = score_fn\n",
    "        self.annealed_step = annealed_step\n",
    "        self.device = device\n",
    "        \n",
    "    # One iteration of annealed step\n",
    "    def _one_annealed_step_iteration(self, x, idx):\n",
    "        '''\n",
    "        x   : perturbated data\n",
    "        idx : step of perturbation schedule\n",
    "        '''\n",
    "        self.score_fn.eval()\n",
    "        z, step_size = torch.randn_like(x).to(device = self.device), self.step_size[idx]\n",
    "        x = x + 0.5 * step_size * self.score_fn(x, idx) + torch.sqrt(step_size) * z\n",
    "        return x\n",
    "        \n",
    "    # One annealed step\n",
    "    def _one_annealed_step(self, x, idx):\n",
    "        '''\n",
    "        x   : perturbated data\n",
    "        idx : step of perturbation schedule\n",
    "        '''\n",
    "        for _ in range(self.annealed_step):\n",
    "            x = self._one_annealed_step_iteration(x, idx)\n",
    "        return x\n",
    "        \n",
    "    # One Langevin Step\n",
    "    def _one_diffusion_step(self, x):\n",
    "        '''\n",
    "        x   : sampling of prior distribution\n",
    "        '''\n",
    "        for idx in range(len(self.process)):\n",
    "            x = self._one_annealed_step(x, idx)\n",
    "            yield x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sampling(self, sampling_number, only_final=False):\n",
    "        '''\n",
    "        only_final : If True, return is an only output of final schedule step \n",
    "        '''\n",
    "        sample = torch.rand([sampling_number, 1, 14, 14]).to(device = self.device)\n",
    "        sampling_list = []\n",
    "        \n",
    "        final = None\n",
    "        for sample in self._one_diffusion_step(sample):\n",
    "            final = sample\n",
    "            if not only_final:\n",
    "                sampling_list.append(final)\n",
    "                \n",
    "\n",
    "        return final if only_final else torch.stack(sampling_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f4f77-1316-4ac7-b28b-da488a854c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:24:40.202116Z",
     "iopub.status.busy": "2024-12-17T10:24:40.201207Z",
     "iopub.status.idle": "2024-12-17T10:24:40.213966Z",
     "shell.execute_reply": "2024-12-17T10:24:40.213074Z",
     "shell.execute_reply.started": "2024-12-17T10:24:40.202066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AnnealedHMCDynamic:\n",
    "    def __init__(self, sigma_min, sigma_max, L, T, score_fn, device, eps=1e-1):\n",
    "        '''\n",
    "        sigma_min : minimum sigmas of perturbation schedule\n",
    "        sigma_max : maximum sigmas of perturbation schedule\n",
    "        L         : leapfrog steps for HMC\n",
    "        T         : annealed steps\n",
    "        score_fn  : trained score network\n",
    "        step_size : coefficient of step size for leapfrog integration\n",
    "        device    : computation device (e.g., 'cuda' or 'cpu')\n",
    "        '''\n",
    "\n",
    "        self.process = torch.exp(torch.linspace(start=math.log(sigma_max), end=math.log(sigma_min), steps = n_steps))\n",
    "        self.step_size = eps * (self.process / self.process[-1] ) ** 2\n",
    "        self.leapfrog_steps = L\n",
    "        self.score_fn = score_fn\n",
    "        self.annealed_steps = T\n",
    "        self.device = 'cuda'\n",
    "\n",
    "    def _leapfrog_integration(self, x, p, sigma, idx):\n",
    "        self.score_fn.eval()  # Ensure the score network is in evaluation mode\n",
    "    \n",
    "        # Step size calculation based on temperature \n",
    "        step_size = self.step_size[idx] \n",
    "        for _ in range(self.leapfrog_steps):\n",
    "            # Half-step update for momentum\n",
    "            score = self.score_fn(x, idx) / sigma\n",
    "            p += 0.5 * step_size * score\n",
    "\n",
    "            # Full-step update for position\n",
    "            x += step_size * p\n",
    "\n",
    "            # Another half-step update for momentum\n",
    "            score = self.score_fn(x, idx) / sigma\n",
    "            p += 0.5 * step_size * score\n",
    "\n",
    "        return x, p\n",
    "\n",
    "    def _metropolis_hastings(self, x, p, x_new, p_new, sigma, idx):\n",
    "        '''\n",
    "        Apply Metropolis-Hastings criterion to accept/reject new states.\n",
    "        x, p     : current position and momentum\n",
    "        x_new, p_new : proposed position and momentum\n",
    "        sigma    : current noise level\n",
    "        idx      : step of perturbation schedule\n",
    "        '''\n",
    "\n",
    "        # Compute Hamiltonians (using the provided equation form)\n",
    "        current_score = self.score_fn(x, idx) / sigma\n",
    "        proposed_score = self.score_fn(x_new, idx) / sigma\n",
    "\n",
    "        current_hamiltonian = 0.5 * torch.sum(p ** 2) + 0.5 * torch.sum(current_score ** 2)\n",
    "        proposed_hamiltonian = 0.5 * torch.sum(p_new ** 2) + 0.5 * torch.sum(proposed_score ** 2)\n",
    "\n",
    "        # Compute acceptance probability using the Metropolis-Hastings formula\n",
    "        acceptance_prob = torch.exp(current_hamiltonian - proposed_hamiltonian)\n",
    "        if torch.rand(1).item() < acceptance_prob:\n",
    "            return x_new  \n",
    "        return x  \n",
    "\n",
    "    def _one_annealed_step(self, x, idx):\n",
    "        '''\n",
    "        Perform one step of annealed HMC.\n",
    "        x   : perturbated data\n",
    "        idx : step of perturbation schedule\n",
    "        '''\n",
    "        sigma = self.process[idx]\n",
    "        p = torch.randn_like(x).to(self.device)  # Initialize momentum\n",
    "        x_new, p_new = self._leapfrog_integration(x, p, sigma, idx)\n",
    "        x = self._metropolis_hastings(x, p, x_new, p_new, sigma, idx)\n",
    "        return x\n",
    "\n",
    "    def _one_perturbation_step(self, x):\n",
    "        '''\n",
    "        Perform annealing through all steps of the schedule.\n",
    "        x : initial samples\n",
    "        '''\n",
    "        for idx in range(len(self.process)):\n",
    "            for _ in range(self.annealed_steps):\n",
    "                x = self._one_annealed_step(x, idx)\n",
    "            yield x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sampling(self, sampling_number, only_final=True):\n",
    "        '''\n",
    "        Generate samples using Annealed HMC.\n",
    "        sampling_number : Number of samples to generate.\n",
    "        only_final      : If True, return only the final sample.\n",
    "        '''\n",
    "        # Initialize samples from the prior distribution\n",
    "        #sample = (torch.rand([sampling_number, 2]).to(self.device) - 0.5) * 2\n",
    "        sample = torch.rand([sampling_number, 1, 14, 14]).to(device = self.device)\n",
    "        sampling_list = []\n",
    "\n",
    "        final = None\n",
    "        for sample in self._one_perturbation_step(sample):\n",
    "            final = sample\n",
    "            if not only_final:\n",
    "                sampling_list.append(final)\n",
    "\n",
    "        return final if only_final else torch.stack(sampling_list)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hairy-station",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:24:42.222769Z",
     "iopub.status.busy": "2024-12-17T10:24:42.222429Z",
     "iopub.status.idle": "2024-12-17T10:24:42.230749Z",
     "shell.execute_reply": "2024-12-17T10:24:42.229856Z",
     "shell.execute_reply.started": "2024-12-17T10:24:42.222741Z"
    },
    "id": "hairy-station",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    \n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        \n",
    "        print('\\r' + '\\t'.join(entries), end = '')\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "closed-reasoning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:24:44.020952Z",
     "iopub.status.busy": "2024-12-17T10:24:44.020509Z",
     "iopub.status.idle": "2024-12-17T10:24:44.030211Z",
     "shell.execute_reply": "2024-12-17T10:24:44.029138Z",
     "shell.execute_reply.started": "2024-12-17T10:24:44.020906Z"
    },
    "id": "closed-reasoning",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def imshow(sample, sampling_number = 64):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    clear_output()\n",
    "    row_number = int(math.sqrt(sampling_number))\n",
    "    col_number = int(math.sqrt(sampling_number))\n",
    "    sample = sample[:sampling_number].detach().cpu().numpy()\n",
    "    shape = sample.shape\n",
    "    show_sample = np.zeros([row_number * shape[2], col_number * shape[3] ]).astype(np.float32)\n",
    "    for row in range(row_number):\n",
    "        for col in range(col_number):\n",
    "            sample_ = sample[row + col * row_number][0]\n",
    "            show_sample[ row * shape[2] : (row+1) * shape[2], col * shape[3] : (col+1) * shape[3] ] = (sample_ - sample_.min()) / (sample_.max() - sample_.min()) * 255\n",
    "            \n",
    "    show_sample = show_sample.astype(np.uint8)\n",
    "    plt.axis(False)\n",
    "    plt.imshow(show_sample, cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-european",
   "metadata": {
    "id": "industrial-european"
   },
   "source": [
    "# Train Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ucbcaRWOV77",
   "metadata": {
    "id": "6ucbcaRWOV77"
   },
   "source": [
    "## Hyperparameter of model and perturbation process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "USwvMnniOXDz",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:24:52.662631Z",
     "iopub.status.busy": "2024-12-17T10:24:52.661848Z",
     "iopub.status.idle": "2024-12-17T10:24:52.735231Z",
     "shell.execute_reply": "2024-12-17T10:24:52.734314Z",
     "shell.execute_reply.started": "2024-12-17T10:24:52.662597Z"
    },
    "id": "USwvMnniOXDz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# epsilon of step size\n",
    "eps = 1e-4\n",
    "\n",
    "# sigma min and max of Langevin dynamic\n",
    "sigma_min = 0.005\n",
    "sigma_max = 10\n",
    "\n",
    "# Langevin step size and Annealed size\n",
    "n_steps = 10\n",
    "annealed_step = 100\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Lsbyx2H1Ocqi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:26:23.519638Z",
     "iopub.status.busy": "2024-12-17T10:26:23.518995Z",
     "iopub.status.idle": "2024-12-17T10:26:23.900450Z",
     "shell.execute_reply": "2024-12-17T10:26:23.899414Z",
     "shell.execute_reply.started": "2024-12-17T10:26:23.519602Z"
    },
    "id": "Lsbyx2H1Ocqi",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = Model(device, n_steps, sigma_min, sigma_max)\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "#dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, n_steps, annealed_step, model, device, eps=eps)\n",
    "#dynamic =  AnnealedHMCDynamic(sigma_min, sigma_max, n_steps, leapfrog_steps, model, device, step_lr=0.1)\n",
    "dynamic = AnnealedHMCDynamic(sigma_min=0.01, sigma_max=1.0, L=10, T=20, score_fn=model, device='cuda', eps=eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OkXQPnE0OoHo",
   "metadata": {
    "id": "OkXQPnE0OoHo"
   },
   "source": [
    "## Hyperparameter of Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "T_bHrz8pOdLc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:26:26.198407Z",
     "iopub.status.busy": "2024-12-17T10:26:26.197815Z",
     "iopub.status.idle": "2024-12-17T10:26:28.964636Z",
     "shell.execute_reply": "2024-12-17T10:26:28.963717Z",
     "shell.execute_reply.started": "2024-12-17T10:26:26.198355Z"
    },
    "id": "T_bHrz8pOdLc",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 42578825.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 1119532.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 10532386.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 3082111.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((14, 14)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "dataset = torchvision.datasets.MNIST(root = './MNIST', train=True, download=True, transform = transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = 256, drop_last = True)\n",
    "dataiterator = iter(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-shopper",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:46:44.704640Z",
     "iopub.status.busy": "2024-12-17T10:46:44.703701Z",
     "iopub.status.idle": "2024-12-17T10:46:44.710467Z",
     "shell.execute_reply": "2024-12-17T10:46:44.709417Z",
     "shell.execute_reply.started": "2024-12-17T10:46:44.704589Z"
    },
    "id": "gross-shopper",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total_iteration = 10000\n",
    "current_iteration = 0\n",
    "display_iteration = 100\n",
    "sampling_number = 16\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "only_final = True\n",
    "\n",
    "\n",
    "losses = AverageMeter('Loss', ':.4f')\n",
    "progress = ProgressMeter(total_iteration, [losses], prefix='Iteration ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import utils\n",
    "from PIL import Image\n",
    "import time\n",
    "def save_image(im,name):\n",
    "    normalized = im-torch.min(im)\n",
    "    normalized = normalized/torch.max(normalized)\n",
    "    utils.save_image(normalized,name)\n",
    "#save_image(im,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-newark",
   "metadata": {
    "id": "worthy-newark"
   },
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805ec3c-8096-456e-8465-3a6ecebbd093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:46:55.260120Z",
     "iopub.status.busy": "2024-12-17T10:46:55.259775Z",
     "iopub.status.idle": "2024-12-17T11:12:32.572581Z",
     "shell.execute_reply": "2024-12-17T11:12:32.571566Z",
     "shell.execute_reply.started": "2024-12-17T10:46:55.260088Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling time for iteration 11000: 141.5284 seconds\n",
      "Mean sampling time: 141.6132 seconds\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "sampling_times = []  # To store sampling times\n",
    "\n",
    "while current_iteration != total_iteration:\n",
    "    model.train()\n",
    "    try:\n",
    "        data = next(dataiterator)\n",
    "    except:\n",
    "        dataiterator = iter(dataloader)\n",
    "        data = next(dataiterator)\n",
    "    data = data[0].to(device=device)\n",
    "    loss = model.loss_fn(data)\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    losses.update(loss.item())\n",
    "    progress.display(current_iteration)\n",
    "    current_iteration += 1\n",
    "    \n",
    "    if current_iteration % display_iteration == 0:\n",
    "        # Start the timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        dynamic = AnnealedHMCDynamic(sigma_min=0.01, sigma_max=1.0, L=10, T=20, score_fn=model, device='cuda', eps=eps)\n",
    "        sample = dynamic.sampling(sampling_number, only_final=True)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        sampling_times.append(elapsed_time)\n",
    "        \n",
    "        imshow(sample, sampling_number)\n",
    "        save_image(im=sample, name='/kaggle/working/imghmc' + str(current_iteration) + '.jpg')\n",
    "        losses.reset()\n",
    "        \n",
    "        print(f\"Sampling time for iteration {current_iteration}: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "    # Save the model weights periodically\n",
    "    model_save_path = '/kaggle/working/model_weights.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# Compute the mean sampling time after the loop ends\n",
    "if sampling_times:\n",
    "    mean_sampling_time = sum(sampling_times) / len(sampling_times)\n",
    "    print(f\"Mean sampling time: {mean_sampling_time:.4f} seconds\")\n",
    "else:\n",
    "    print(\"No sampling time recorded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d25d270-c9a7-44c7-9730-97308672be12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:36:00.608456Z",
     "iopub.status.busy": "2024-12-17T10:36:00.607746Z",
     "iopub.status.idle": "2024-12-17T10:36:00.678820Z",
     "shell.execute_reply": "2024-12-17T10:36:00.677921Z",
     "shell.execute_reply.started": "2024-12-17T10:36:00.608415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Saving image\n",
    "im = sample[0, 0].detach().cpu().numpy() \n",
    "save_image(im=sample,name='/kaggle/working/imghmc10200.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-bonus",
   "metadata": {
    "id": "fourth-bonus"
   },
   "source": [
    "## Inference Phase (Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5768fa8b-0e90-4abc-a093-4775e490a669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T10:27:36.467819Z",
     "iopub.status.busy": "2024-12-17T10:27:36.467193Z",
     "iopub.status.idle": "2024-12-17T10:27:36.859304Z",
     "shell.execute_reply": "2024-12-17T10:27:36.858463Z",
     "shell.execute_reply.started": "2024-12-17T10:27:36.467783Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recover saved weights\n",
    "model_save_path = '/kaggle/input/wegiths/model_weights_dsm_hmc_mnist.pth'\n",
    "model.load_state_dict(torch.load(model_save_path,weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987f06e",
   "metadata": {},
   "source": [
    "Comparison between sampling time for Langevin dynamic and HMC (HMC takes more time then Langevin for one step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a71150c0-e2da-4760-97b0-78e2d1b30dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T09:32:07.048710Z",
     "iopub.status.busy": "2024-12-17T09:32:07.048330Z",
     "iopub.status.idle": "2024-12-17T09:32:39.710867Z",
     "shell.execute_reply": "2024-12-17T09:32:39.709967Z",
     "shell.execute_reply.started": "2024-12-17T09:32:07.048666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling completed in 32.6538 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "sampling_number = 16\n",
    "only_final = True\n",
    "dynamic = dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, n_steps, annealed_step, model, device, eps=eps)\n",
    "start_time = time.time()\n",
    "sample = dynamic.sampling(sampling_number, only_final=True)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Sampling completed in {elapsed_time:.4f} seconds.\")\n",
    "#imshow(sample, sampling_number)\n",
    "im = sample[0, 0].detach().cpu().numpy() \n",
    "save_image(im=sample,name='/kaggle/working/img2langevin.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "military-beach",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T09:36:35.830600Z",
     "iopub.status.busy": "2024-12-17T09:36:35.829984Z",
     "iopub.status.idle": "2024-12-17T09:38:51.921997Z",
     "shell.execute_reply": "2024-12-17T09:38:51.921165Z",
     "shell.execute_reply.started": "2024-12-17T09:36:35.830568Z"
    },
    "id": "military-beach",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling completed in 136.0832 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "sampling_number = 16\n",
    "only_final = True\n",
    "dynamic = AnnealedHMCDynamic(sigma_min=0.01, sigma_max=1.0, L=10, T=20, score_fn=model, device='cuda', eps=eps)\n",
    "start_time = time.time()\n",
    "sample = dynamic.sampling(sampling_number, only_final=True)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Sampling completed in {elapsed_time:.4f} seconds.\")\n",
    "#imshow(sample, sampling_number)\n",
    "im = sample[0, 0].detach().cpu().numpy() \n",
    "save_image(im=sample,name='/kaggle/working/img2hmc.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-milwaukee",
   "metadata": {
    "id": "scientific-milwaukee"
   },
   "outputs": [],
   "source": [
    "sampling_number = 4\n",
    "only_final = False\n",
    "dynamic = AnnealedLangevinDynamic(sigma_min, sigma_max, n_steps, annealed_step, model, device, eps=eps)\n",
    "sample = dynamic.sampling(sampling_number, only_final)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NCSN_MNIST.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6320222,
     "sourceId": 10223489,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
